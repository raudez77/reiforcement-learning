{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from typing import List"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $ Example \\ 1 \\ - \\ Simple \\ Class \\ Enviroment \\ Creation. $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Enviroment \n",
    "class Enviroment:\n",
    "    \"\"\" My First Enviroment\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.step_left = 10\n",
    "\n",
    "    def get_observation(self)-> List[float]:\n",
    "        return [0.0, 0.0, 0.0]\n",
    "\n",
    "    def get_action(self) -> List[int]:\n",
    "        return [0,1]\n",
    "\n",
    "    def is_done(self)-> bool:\n",
    "        return self.step_left == 0\n",
    "\n",
    "    def action(self, action:int)-> float:\n",
    "        if self.is_done():\n",
    "            raise Exception (\"Program Files\")\n",
    "        self.step_left -= 1\n",
    "        return random.random()\n",
    "\n",
    "# Creat Agent \n",
    "class Agent:\n",
    "    \"\"\" My First Agent\"\"\"\n",
    "    def __init__(self):\n",
    "        self.total_reward = 0\n",
    "\n",
    "    def step (self, env:Enviroment):\n",
    "        current_obs = env.get_observation()\n",
    "        actions = env.get_action()\n",
    "        reward = env.action(random.choices(actions))\n",
    "        self.total_reward += reward\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward got: 0.4284\n",
      "Total reward got: 0.7380\n",
      "Total reward got: 1.5419\n",
      "Total reward got: 2.2538\n",
      "Total reward got: 2.8175\n",
      "Total reward got: 3.6967\n",
      "Total reward got: 4.3586\n",
      "Total reward got: 5.3196\n",
      "Total reward got: 6.0401\n",
      "Total reward got: 6.3954\n"
     ]
    }
   ],
   "source": [
    "env = Enviroment()\n",
    "agent = Agent()\n",
    "\n",
    "while not env.is_done():\n",
    "    agent.step(env)\n",
    "\n",
    "    print(\"Total reward got: %.4f\" % agent.total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $ Example \\ 2 \\ - \\ Simple \\ Class \\ Cart Pole. $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classic Control Enviroment : https://www.gymlibrary.dev/api/core/\n",
    "    - Game:  Cart Pole\n",
    "    - Action Space : ndarray with shape (1,) which takes values {0,1} where 0, push cart to the left, and 1, push cart to the right \n",
    "    - Observation space : ndarray with shape(4,) which \n",
    "\n",
    "        |   Num |   Observation |   Min |   Max |\n",
    "        | --- | --- | --- | --- | \n",
    "        |   0   |   Cart Position   |   -4.8    |   4.8 |\n",
    "        |   1   |   Cart Velocity   |   -Inf    |   Inf |\n",
    "        |   2   |   Pole Angle  | ~ -0.418 rad (-24°)   |~ 0.418 rad (24°) |\n",
    "        |   3   |   Pole Angular Velocity   |   -Inf    |   Inf |\n",
    "\n",
    "    -  Episode End\n",
    "        1. Termination: Pole Angle is greater than ±12°\n",
    "\n",
    "        2. Termination: Cart Position is greater than ±2.4 (center of the cart reaches the edge of the display)\n",
    "\n",
    "        3. Truncation: Episode length is greater than 500 (200 for v0)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Episode : 0, Step : 24, Reward : 24.0\n",
      " Episode : 1, Step : 13, Reward : 13.0\n",
      " Episode : 2, Step : 17, Reward : 17.0\n",
      " Episode : 3, Step : 10, Reward : 10.0\n",
      " Episode : 4, Step : 33, Reward : 33.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 24.0, 1: 13.0, 2: 17.0, 3: 10.0, 4: 33.0}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example + Rendering \n",
    "import gymnasium as gym\n",
    "import time\n",
    "env = gym.make(\"CartPole-v1\", render_mode = 'human') \n",
    "\"\"\"rgym.Env.step(self, action: ActType) → Tuple[ObsType, float, bool, bool, dict]\n",
    "render_mode = 'human' to be able to see the animation `note`: not all of them enviroment ara avialble\"\"\"\n",
    "\n",
    "# Rewards, Steps & Observation\n",
    "total_reward = 0.0 # Float\n",
    "intia_state = env.reset() \n",
    "total_episode = 0 \n",
    "total_steps = 0\n",
    "\"\"\" gym.Env.reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None) → Tuple[ObsType, dict]\"\"\"\n",
    "\n",
    "# Train the Agent to Play 5 Episode where each episode have 60 second that are equal to number of steps\n",
    "\n",
    "Stats = {}\n",
    "Episode, second = 5 , 60\n",
    "while total_episode < Episode:\n",
    "\n",
    "    # Step 1. Render & Initiate Actions\n",
    "    env.render()\n",
    "    action_n = env.action_space.sample()\n",
    "    \"\"\"As mentioned in our case 0 for left , 1 for right \"\"\"\n",
    "\n",
    "    # Step 2. Evaluate action into Eviroment \n",
    "    obs, reward, done, _ , _ = env.step(action = action_n) \n",
    "    \"\"\"gym.Env.step(self, action: ActType) → Tuple[ObsType, float, bool, bool, dict]\n",
    "    Accepts an action and returns either a tuple (observation, reward, terminated, truncated, info).\"\"\"\n",
    "\n",
    "    time.sleep(0.085) #  Add time to visulize the Game\n",
    "    total_reward += 1\n",
    "    total_steps += 1\n",
    "\n",
    "    if total_steps == second or done:\n",
    "        print(f\" Episode : {total_episode}, Step : {total_steps}, Reward : {total_reward}\")\n",
    "        Stats[total_episode] = total_reward\n",
    "        total_episode += 1\n",
    "        total_reward = 0.0\n",
    "        total_steps = 0 \n",
    "        if done:\n",
    "            env.reset()  # \n",
    "\n",
    "env.close()\n",
    "Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
